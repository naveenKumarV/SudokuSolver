{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def createMachineDigitsDataset(img_shape):\n",
    "    fonts = [cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            cv2.FONT_HERSHEY_DUPLEX,\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            cv2.FONT_HERSHEY_TRIPLEX,\n",
    "            cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "            cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "            cv2.FONT_HERSHEY_SCRIPT_COMPLEX]\n",
    "    font_sizes = [1, 1.2, 1.4, 1.6, 1.75]\n",
    "    thickness = [1, 2]\n",
    "    dataset = []\n",
    "    for f in fonts:\n",
    "        for s in font_sizes:\n",
    "            for t in thickness:\n",
    "                for i in range(10):\n",
    "                    for x in [4, 3, -3,  2, -2, -4, 1, -1, 0]:\n",
    "                        for y in [4, 3, -3, 2, -2, -4, 1, -1, 0]:\n",
    "                            if s is 1.75 and y is 4:\n",
    "                                y = 3\n",
    "                            img = np.zeros(list(img_shape), dtype=np.float32)\n",
    "                            img[:, :] = 1\n",
    "                            text_size = cv2.getTextSize(str(i), f, s, t)[0]\n",
    "                            textX = (img.shape[1] - text_size[0]) // 2\n",
    "                            textY = (img.shape[0] + text_size[1]) // 2\n",
    "                            img = cv2.putText(img, str(i), (textX + x, textY + y), f, s, [0], t, cv2.LINE_AA)\n",
    "                            dataset.append((img, i))\n",
    "    shuffle(dataset)\n",
    "    images, labels = zip(*dataset)\n",
    "    training = (np.array(images[0:55000], dtype=np.float32), np.array(labels[0:55000], dtype=np.int32))\n",
    "    test = (np.array(images[55000:], dtype=np.float32), np.array(labels[55000:], dtype=np.int32))\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = createMachineDigitsDataset((42, 42))\n",
    "print(train[0].shape)\n",
    "print(test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('machine_digits_dataset', training_input = train[0], training_output = train[1], \n",
    "        test_input = test[0], test_output = test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_one_hot(feature, label):\n",
    "    return (feature, tf.one_hot(label, 10, on_value=1.0, off_value=0.0, dtype=tf.float32, axis=-1))\n",
    "\n",
    "with np.load('machine_digits_dataset.npz') as data:\n",
    "    train = (data[\"training_input\"], data[\"training_output\"])\n",
    "    test = (data[\"test_input\"], data[\"test_output\"])\n",
    "\n",
    "training_dataset = tf.contrib.data.Dataset.from_tensor_slices(train)\n",
    "training_dataset = training_dataset.map(convert_one_hot)\n",
    "training_dataset = training_dataset.repeat()\n",
    "training_dataset = training_dataset.batch(50)\n",
    "\n",
    "\n",
    "test_dataset = tf.contrib.data.Dataset.from_tensor_slices(test)\n",
    "test_dataset = test_dataset.map(convert_one_hot) \n",
    "test_dataset = test_dataset.batch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, name = \"x\")\n",
    "    x_image = tf.reshape(x, [-1, 42, 42, 1])\n",
    "    y = tf.placeholder(tf.float32, name = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv1'):\n",
    "    w1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev = 0.1), name=\"w1\")\n",
    "    b1 = tf.Variable(tf.truncated_normal([32], stddev = 0.1), name=\"b1\")\n",
    "    conv1 = tf.nn.relu(tf.add(tf.nn.conv2d(x_image, w1, strides = [1, 1, 1, 1], padding='SAME'), b1))\n",
    "    \n",
    "    \n",
    "with tf.name_scope('pool1'):\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('conv2'):\n",
    "    w2 = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev = 0.1), name=\"w2\")\n",
    "    b2 = tf.Variable(tf.truncated_normal([64], stddev = 0.1), name=\"b2\")\n",
    "    conv2 = tf.nn.relu(tf.add(tf.nn.conv2d(pool1, w2, strides = [1, 1, 1, 1], padding = 'SAME'), b2))\n",
    "    \n",
    "    \n",
    "with tf.name_scope('pool2'):\n",
    "    pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('fc1'):\n",
    "    w_fc1 = tf.Variable(tf.truncated_normal([11*11*64, 1536], stddev = 0.1), name=\"w_fc1\")\n",
    "    b_fc1 = tf.Variable(tf.truncated_normal([1536], stddev = 0.1), name = \"b_fc1\")\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 11*11*64])\n",
    "    fc1 = tf.nn.relu(tf.add(tf.matmul(pool2_flat, w_fc1), b_fc1))\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "    fc1_drop = tf.nn.dropout(fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('fc2'):\n",
    "    w_fc2 = tf.Variable(tf.truncated_normal([1536, 10], stddev = 0.1), name=\"w_fc2\")\n",
    "    b_fc2 = tf.Variable(tf.truncated_normal([10], stddev = 0.1), name=\"b_fc2\")\n",
    "\n",
    "    y_ = tf.add(tf.matmul(fc1_drop, w_fc2), b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = y_, name = \"cross_entropy\"))\n",
    "training_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "num_correct = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f47b3d6860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_iter = 1\n",
    "loss = []\n",
    "test_size = 9800\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iterator = training_dataset.make_one_shot_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    for i in range(num_iter):\n",
    "        if i % 100 is 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            batch = sess.run(next_element)\n",
    "            _, training_loss = sess.run([training_step, cross_entropy], feed_dict = {x : batch[0], y : batch[1], keep_prob : 0.5})\n",
    "            loss.append(training_loss)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        \n",
    "    plt.plot(list(range(num_iter)), loss)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    iterator = test_dataset.make_one_shot_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    total_correct = 0\n",
    "    while True:\n",
    "        try:\n",
    "            batch = sess.run(next_element)\n",
    "            total_correct = total_correct + sess.run(num_correct, feed_dict = {x : batch[0], y : batch[1], keep_prob : 1.0})\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    print(total_correct / test_size)\n",
    "    save_path = saver.save(sess, \"F:\\\\Code\\\\Python\\\\machine_digits_model\\\\machine_digits_classifier.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
